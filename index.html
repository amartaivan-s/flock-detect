<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Real-Time Moving Flock Detection in Pedestrian Trajectories</title>
<style>
  :root { --ink:#222; --ink2:#444; --link:#0b6cff; --rule:#eee; }
  body {
    font-family: Arial, system-ui, -apple-system, "Segoe UI", Roboto, sans-serif;
    max-width: 960px; margin: auto; padding: 24px; line-height: 1.65; color: var(--ink);
  }
  h1 { margin: 0 0 8px; }
  .sub { color: var(--ink2); margin: 0 0 20px; }
  .hero {
  width: 60%;
  height: auto;
  border-radius: 8px;
  margin: 16px auto;
  display: block; }
  .section-title {
    margin-top: 28px; color: var(--ink2);
    border-bottom: 2px solid var(--rule); padding-bottom: 6px;
  }
  .gif-container {
      text-align: center;
      margin: 2em 0;
  }
  ul { margin: 8px 0 0 20px; }
  a { color: var(--link); text-decoration: none; }
  a:hover { text-decoration: underline; }
  .meta { font-size: 0.95rem; color: var(--ink2); }
  .details a { display:inline-block; margin: 8px 16px 0 0; font-weight: 600; }
  .tile {
    display:grid; gap:16px; grid-template-columns: 1fr; margin-top:10px;
  }
  .pill {
    display:inline-block; padding: 2px 8px; border-radius: 999px;
    background:#f2f5ff; color:#274cdb; font-size: 12px; margin-right:6px;
  }
  @media (min-width: 720px) { .tile { grid-template-columns: 2fr 3fr; } }
  code.inline { background:#f6f8fa; padding:2px 6px; border-radius:4px; }
</style>
</head>
<body>
<p><a href="https://amartaivan-s.github.io/">üè† Home</a></p>

<h1>üöÄ Real-Time Moving Flock Detection in Pedestrian Trajectories</h1>
<p class="sub meta">
  Sequential deep learning for online detection of collective motion in crowds
</p>

<h2 class="section-title">Overview</h2>
<p>
This project studies <strong>real-time flock detection</strong> in multi-pedestrian trajectories using
<strong>sequential deep learning models</strong> (RNNs, LSTMs, and Transformers).
It follows a <strong>two‚Äëstage pipeline</strong>:
(1) a pre‚Äëtrained <em>binary pairwise classifier</em> over trajectories, and
(2) a <em>grouping stage</em> that leverages learned representations to dynamically identify multi‚Äëagent flocks.
Validated on real‚Äëworld group movement datasets, the method is designed to be robust across
varying sequence lengths, diverse motion patterns, and noisy environments.
</p>

  <div class="gif-container">
    <img src="main_flock.png" alt="Method Overview Diagram" class="hero">
    <p><small>Figure: Proposed method overview.</small></p>
  </div>

<div class="tile">
  <div>
    <h2 class="section-title">Output & Results</h2>
    <ul>
      <li>Online detection of <strong>moving flocks</strong> from streaming trajectories.</li>
      <li>Pairwise embeddings ‚Üí <strong>dynamic group inference</strong> (flocks, with extensibility to convoys/swarms).</li>
      <li>Stable performance across sequence lengths and crowd conditions.</li>
      <li>Designed for <strong>real-time</strong> operation in practical settings.</li>
    </ul>
  </div>
  <div>
    <img src="sample_flock.png" alt="Sample Flock Detection Results." class="hero">
    Sample Flock Detection Results 

  </div>

</div>

<h2 class="section-title">Details & Resources</h2>
<p class="details">
  <a href="https://arxiv.org/abs/2502.15252" target="_blank">üìÑ Read the full paper</a>
</p>

<h2 class="section-title">How to Cite</h2>
<p class="meta">
Amartaivan Sanjjamts, Hiroshi Morita, Togootogtokh Enkhtogtokh,
<i>"Real-Time Moving Flock Detection in Pedestrian Trajectories Using Sequential Deep Learning Models"</i>,
arXiv:2502.15252, 2025. DOI: 10.48550/arXiv.2502.15252.
</p>

<footer style="margin-top: 3em; font-size: 0.85em; color: #666;">
    Last updated: June 2025 ‚Ä¢ Author: Sanjjamts Amartaivan
  </footer>


</body>
</html>
